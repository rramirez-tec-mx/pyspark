{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pySpark Regression Analysis-Colab.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"sq8U3BtmhtRx"},"source":["*italicized text*\n","**bold**\n","## Instalar pySpark en Google Colab\n","\n","To run spark in Colab, we need to first install all the dependencies in Colab environment i.e. Apache Spark 2.3.2 with hadoop 2.7, Java 8 and Findspark to locate the spark in the system. The tools installation can be carried out inside the Jupyter Notebook of the Colab. One important note is that if you are new in Spark, it is better to avoid Spark 2.4.0 version since some people have already complained about its compatibility issue with python. \n","Follow the steps to install the dependencies:"]},{"cell_type":"code","metadata":{"id":"lh5NCoc8fsSO","executionInfo":{"status":"ok","timestamp":1648602507159,"user_tz":360,"elapsed":35296,"user":{"displayName":"Raúl Valente Ramírez Velarde","userId":"12033984646533146741"}}},"source":["!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q https://downloads.apache.org/spark/spark-2.4.8/spark-2.4.8-bin-hadoop2.7.tgz\n","!tar xf spark-2.4.8-bin-hadoop2.7.tgz\n","!pip install -q findspark"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ILheUROOhprv"},"source":["Now that you installed Spark and Java in Colab, it is time to set the environment path which enables you to run Pyspark in your Colab environment. Set the location of Java and Spark by running the following code:"]},{"cell_type":"code","metadata":{"id":"v1b8k_OVf2QF","executionInfo":{"status":"ok","timestamp":1648602507160,"user_tz":360,"elapsed":7,"user":{"displayName":"Raúl Valente Ramírez Velarde","userId":"12033984646533146741"}}},"source":["#All imports\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.8-bin-hadoop2.7\""],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KwrqMk3HiMiE"},"source":["Run a local spark session to test your installation:"]},{"cell_type":"code","metadata":{"id":"9_Uz1NL4gHFx","executionInfo":{"status":"ok","timestamp":1648602515580,"user_tz":360,"elapsed":8426,"user":{"displayName":"Raúl Valente Ramírez Velarde","userId":"12033984646533146741"}}},"source":["import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"_csfAewrUhy5","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1648602515581,"user_tz":360,"elapsed":8,"user":{"displayName":"Raúl Valente Ramírez Velarde","userId":"12033984646533146741"}},"outputId":"5aee2d47-640c-4835-93c0-bbebdd3c2477"},"source":["# to retrieve SparkContext version\n","spark.version"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.4.8'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"xkJwSNnOTBVg"},"source":["## Importar Google Drive"]},{"cell_type":"code","metadata":{"id":"t5L2W2itTzwj"},"source":["#from google.colab import files\n","#files.upload()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pdz6J9-gTCA2","executionInfo":{"status":"ok","timestamp":1648602533178,"user_tz":360,"elapsed":17603,"user":{"displayName":"Raúl Valente Ramírez Velarde","userId":"12033984646533146741"}},"outputId":"f2176374-7e02-41a6-f7ca-9c66a5821d06"},"source":["#Mount Google drive, read local file. The file was previously uploaded to Google Drive\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","%ls"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/  \u001b[01;34mspark-2.4.8-bin-hadoop2.7\u001b[0m/  spark-2.4.8-bin-hadoop2.7.tgz\n"]}]},{"cell_type":"markdown","metadata":{"id":"8cwsA_X4THpr"},"source":["## Importar Datos"]},{"cell_type":"markdown","metadata":{"id":"gJHytyIh4-Ke"},"source":["Base de datos Boston Housing\n","\n","El conjunto de datos de este modelo proviene del repositorio “UCI Machine Learning”. Estos datos se recopilaron en in 1978, y cada una de las 506 entradas representan datos agregados de 14 características de casas en diversos barrios de Boston. La base de datos Boston Housing contiene los datos originales de Harrison y Rubinfeld (1979). \n","\n","Los datos tienen las siguientes características, siendo medv la variable de objetivo o independiente\n","\n","crim - Crimen per cápita por ciudad\n","\n","zn - proporción de terrenos residenciales divididos en zonas para lotes de más de 25,000 pies cuadrados\n","\n","indus - proporción de acres de negocios no minoristas por ciudad\n","\n","chas - variable ficticia de Charles River (= 1 si el tramo limita el río, 0 de lo contrario)\n","\n","nox - concentración de óxidos nítricos (partes por 10 millones)\n","\n","rm - número promedio de habitaciones por vivienda\n","\n","age - proporción de unidades ocupadas por sus propietarios construidas antes de 1940\n","\n","dis - Distancias desproporcionadas a cinco centros de empleo de Boston\n","\n","rad - índice de accesibilidad a las autopistas radiales\n","\n","tax - tasa de impuesto a la propiedad de valor completo por USD 10,000\n","\n","ptratio - colegios por localidad \n","\n","black - 1000 (B - 0,63)^ 2, donde B es la proporción de negros por ciudad\n","\n","lstat - porcentaje de estado inferior de la población\n","\n","medv - valor mediano de las viviendas ocupadas por sus propietarios en USD 1000"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x2Zd_yatTsBy","executionInfo":{"status":"ok","timestamp":1648602560744,"user_tz":360,"elapsed":7442,"user":{"displayName":"Raúl Valente Ramírez Velarde","userId":"12033984646533146741"}},"outputId":"57376db1-737b-479e-b90b-e6db90a06769"},"source":["path_csv=\"/content/drive/MyDrive/Colab Notebooks/Certificado Data Science y AI (DSA) Live/BostonHousing.csv\"\n","dataset = spark.read.csv(path_csv,inferSchema=True, header =True)\n","dataset.show(10)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+----+-----+----+-----+-----+-----+------+---+---+-------+------+-----+----+\n","|   crim|  zn|indus|chas|  nox|   rm|  age|   dis|rad|tax|ptratio| black|lstat|medv|\n","+-------+----+-----+----+-----+-----+-----+------+---+---+-------+------+-----+----+\n","|0.00632|18.0| 2.31|   0|0.538|6.575| 65.2|  4.09|  1|296|   15.3| 396.9| 4.98|24.0|\n","|0.02731| 0.0| 7.07|   0|0.469|6.421| 78.9|4.9671|  2|242|   17.8| 396.9| 9.14|21.6|\n","|0.02729| 0.0| 7.07|   0|0.469|7.185| 61.1|4.9671|  2|242|   17.8|392.83| 4.03|34.7|\n","|0.03237| 0.0| 2.18|   0|0.458|6.998| 45.8|6.0622|  3|222|   18.7|394.63| 2.94|33.4|\n","|0.06905| 0.0| 2.18|   0|0.458|7.147| 54.2|6.0622|  3|222|   18.7| 396.9| 5.33|36.2|\n","|0.02985| 0.0| 2.18|   0|0.458| 6.43| 58.7|6.0622|  3|222|   18.7|394.12| 5.21|28.7|\n","|0.08829|12.5| 7.87|   0|0.524|6.012| 66.6|5.5605|  5|311|   15.2| 395.6|12.43|22.9|\n","|0.14455|12.5| 7.87|   0|0.524|6.172| 96.1|5.9505|  5|311|   15.2| 396.9|19.15|27.1|\n","|0.21124|12.5| 7.87|   0|0.524|5.631|100.0|6.0821|  5|311|   15.2|386.63|29.93|16.5|\n","|0.17004|12.5| 7.87|   0|0.524|6.004| 85.9|6.5921|  5|311|   15.2|386.71| 17.1|18.9|\n","+-------+----+-----+----+-----+-----+-----+------+---+---+-------+------+-----+----+\n","only showing top 10 rows\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"JEb4HTRwiaJx"},"source":["## Modelos de Regresion Lineal y No Lineal\n","\n","\n","Linear Regression model is one the oldest and widely used machine learning approach which assumes a relationship between dependent and independent variables. For example, a modeler might want to predict the forecast of the rain based on the humidity ratio. Linear Regression consists of the best fitting line through the scattered points on the graph and the best fitting line is known as the regression line.\n","\n","The goal of this exercise to predict the housing prices by the given features. Let's predict the prices of the Boston Housing dataset by considering MEDV as the output variable and all the other variables as input.\n","\n","Download the dataset from [here](https://github.com/asifahmed90/pyspark-ML-in-Colab/blob/master/BostonHousing.csv) and keep it somewhere on your computer. Load the dataset into your Colab directory from your local system:"]},{"cell_type":"markdown","metadata":{"id":"21D9EANUvnwF"},"source":["For our linear regression model we need to import two modules from Pyspark i.e. Vector Assembler and Linear Regression. Vector Assembler is a transformer that assembles all the features into one vector from multiple columns that contain type double. We could have used StringIndexer if any of our columns contains string values to convert it into numeric values. Luckily, the BostonHousing dataset only contains double values, so we don't need to worry about StringIndexer for now."]},{"cell_type":"code","metadata":{"id":"0ZeJ7WQCgM8g","executionInfo":{"status":"ok","timestamp":1648603267282,"user_tz":360,"elapsed":414,"user":{"displayName":"Raúl Valente Ramírez Velarde","userId":"12033984646533146741"}}},"source":["from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.regression import LinearRegression"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UJLoAfqVv8-E"},"source":["Notice that we used InferSchema inside read.csv mofule. InferSchema enables us to infer automatically different data types for each column.\n","\n","Let us print look into the dataset to see the data types of each column:"]},{"cell_type":"code","metadata":{"id":"Gok1FXWugYkE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648603268811,"user_tz":360,"elapsed":122,"user":{"displayName":"Raúl Valente Ramírez Velarde","userId":"12033984646533146741"}},"outputId":"61ba8d21-f643-4198-a448-945676993442"},"source":["dataset.printSchema()"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- crim: double (nullable = true)\n"," |-- zn: double (nullable = true)\n"," |-- indus: double (nullable = true)\n"," |-- chas: integer (nullable = true)\n"," |-- nox: double (nullable = true)\n"," |-- rm: double (nullable = true)\n"," |-- age: double (nullable = true)\n"," |-- dis: double (nullable = true)\n"," |-- rad: integer (nullable = true)\n"," |-- tax: integer (nullable = true)\n"," |-- ptratio: double (nullable = true)\n"," |-- black: double (nullable = true)\n"," |-- lstat: double (nullable = true)\n"," |-- medv: double (nullable = true)\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"3L9VJqsHwEGf"},"source":["Next step is to convert all the features from different columns into a single column and let's call this new vector column as 'Attributes' in the outputCol."]},{"cell_type":"code","metadata":{"id":"sKSqdT9QgkfD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648603271404,"user_tz":360,"elapsed":895,"user":{"displayName":"Raúl Valente Ramírez Velarde","userId":"12033984646533146741"}},"outputId":"b6a54d16-1d4f-4041-b2a6-d629d6fb70aa"},"source":["#Input all the features in one vector column\n","assembler = VectorAssembler(inputCols=['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'black', 'lstat'], outputCol = 'Attributes')\n","\n","output = assembler.transform(dataset)\n","\n","#Input vs Output\n","finalized_data = output.select(\"Attributes\",\"medv\")\n","\n","finalized_data.show(10)"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+----+\n","|          Attributes|medv|\n","+--------------------+----+\n","|[0.00632,18.0,2.3...|24.0|\n","|[0.02731,0.0,7.07...|21.6|\n","|[0.02729,0.0,7.07...|34.7|\n","|[0.03237,0.0,2.18...|33.4|\n","|[0.06905,0.0,2.18...|36.2|\n","|[0.02985,0.0,2.18...|28.7|\n","|[0.08829,12.5,7.8...|22.9|\n","|[0.14455,12.5,7.8...|27.1|\n","|[0.21124,12.5,7.8...|16.5|\n","|[0.17004,12.5,7.8...|18.9|\n","+--------------------+----+\n","only showing top 10 rows\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"dNgFCto2wHLd"},"source":["Here, 'Attributes' are in the input features from all the columns and 'medv' is the target column.\n","Next, we should split the training and testing data according to our dataset (0.8 and 0.2 in this case)."]},{"cell_type":"code","metadata":{"id":"kwe1VT0UNOIN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648603277192,"user_tz":360,"elapsed":3542,"user":{"displayName":"Raúl Valente Ramírez Velarde","userId":"12033984646533146741"}},"outputId":"5dfa4082-4d33-48ff-a07f-74b2dd9e30f0"},"source":["#Split training and testing data\n","train_data,test_data = finalized_data.randomSplit([0.8,0.2])\n","\n","\n","regressor = LinearRegression(featuresCol = 'Attributes', labelCol = 'medv')\n","\n","#Learn to fit the model from training set\n","regressor = regressor.fit(train_data)\n","\n","#To predict the prices on testing set\n","#pred_lr = regressor.evaluate(test_data)\n","\n","#Predict the model\n","#pred_lr.predictions.show(10)\n","\n","#It can also be done in this way\n","pred_lr = regressor.transform(test_data)\n","pred_lr.select('Attributes', 'medv', 'prediction').show(15)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+----+------------------+\n","|          Attributes|medv|        prediction|\n","+--------------------+----+------------------+\n","|[0.00632,18.0,2.3...|24.0|29.737074286701933|\n","|[0.00906,90.0,2.9...|32.2| 31.50878230441754|\n","|[0.01301,35.0,1.5...|32.7| 30.19710136062311|\n","|[0.01951,17.5,1.3...|33.0|23.186315589682287|\n","|[0.02055,85.0,0.7...|24.7|24.350928554693756|\n","|[0.02729,0.0,7.07...|34.7|30.521622402464057|\n","|[0.02899,40.0,1.2...|26.6|21.745583918966155|\n","|[0.03113,0.0,4.39...|17.5|16.182746874540307|\n","|[0.0315,95.0,1.47...|34.9|29.761912760779715|\n","|[0.03237,0.0,2.18...|33.4|28.401690431332206|\n","|[0.03359,75.0,2.9...|34.9| 33.99636786407778|\n","|[0.03466,35.0,6.0...|19.4| 23.06345162584452|\n","|[0.03548,80.0,3.6...|20.9| 21.25177868815085|\n","|[0.03738,0.0,5.19...|20.7|21.220851388122092|\n","|[0.03871,52.5,5.3...|23.2|26.804837096689347|\n","+--------------------+----+------------------+\n","only showing top 15 rows\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0rVmn_NA7R9R","executionInfo":{"status":"ok","timestamp":1648603281197,"user_tz":360,"elapsed":559,"user":{"displayName":"Raúl Valente Ramírez Velarde","userId":"12033984646533146741"}},"outputId":"e2177e49-65f3-44e8-a277-e8c19d0427dd"},"source":["import numpy as np\n","print (\"Note: the last rows are the information for Intercept\")\n","print (\"##\",\"-------------------------------------------------\")\n","print (\"##\",\"  Estimate   |   Std.Error | t Values  |  P-value\")\n","coef = np.append(list(regressor.coefficients),regressor.intercept)\n","Summary=regressor.summary\n","\n","for i in range(len(Summary.pValues)):\n","    print (\"##\",'{:10.6f}'.format(coef[i]),\\\n","    '{:10.6f}'.format(Summary.coefficientStandardErrors[i]),\\\n","    '{:8.3f}'.format(Summary.tValues[i]),\\\n","    '{:10.6f}'.format(Summary.pValues[i]))\n","\n","print (\"##\",'---')\n","print (\"##\",\"Mean squared error: % .6f\" \\\n","        % Summary.meanSquaredError, \", \\\n","        RMSE: % .6f\" \\\n","        % Summary.rootMeanSquaredError )\n","print (\"##\",\"Multiple R-squared: %f\" % Summary.r2, \", \\\n","        Total iterations: %i\"% Summary.totalIterations)"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Note: the last rows are the information for Intercept\n","## -------------------------------------------------\n","##   Estimate   |   Std.Error | t Values  |  P-value\n","##  -0.115210   0.034041   -3.384   0.000784\n","##   0.045146   0.015063    2.997   0.002897\n","##   0.032864   0.069903    0.470   0.638515\n","##   2.814747   0.883792    3.185   0.001563\n","## -19.010502   4.106463   -4.629   0.000005\n","##   4.043601   0.463514    8.724   0.000000\n","##  -0.000252   0.014394   -0.018   0.986024\n","##  -1.522442   0.224414   -6.784   0.000000\n","##   0.317895   0.074365    4.275   0.000024\n","##  -0.012904   0.004231   -3.050   0.002441\n","##  -0.982464   0.146130   -6.723   0.000000\n","##   0.008421   0.002937    2.868   0.004357\n","##  -0.499863   0.054961   -9.095   0.000000\n","##  36.413644   5.710907    6.376   0.000000\n","## ---\n","## Mean squared error:  21.628740 ,         RMSE:  4.650671\n","## Multiple R-squared: 0.744075 ,         Total iterations: 1\n"]}]},{"cell_type":"markdown","metadata":{"id":"Y3vYyp5dwOm_"},"source":["We can also print the coefficient and intercept of the regression model by using the following command:"]},{"cell_type":"code","metadata":{"id":"Eja1BLiaTThT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631656768037,"user_tz":300,"elapsed":4,"user":{"displayName":"Raúl Valente Ramírez Velarde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsTl_7K9-nt2Nuy6x1vdia7WL7K2k6yyrhPeq3=s64","userId":"12033984646533146741"}},"outputId":"5d7857d7-a770-4890-8c74-6b6197013861"},"source":["#coefficient of the regression model\n","#coeff = regressor.coefficients\n","\n","#X and Y intercept\n","#intr = regressor.intercept\n","\n","print (\"The coefficient of the model is : \", regressor.coefficients)\n","print (\"The Intercept of the model is : \", regressor.intercept)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The coefficient of the model is :  [-0.1043061977316422,0.04592454511455656,0.039942019197666136,2.1598717051076752,-19.011240129760672,3.9056221349873566,0.002665470978042072,-1.4729229068444338,0.28224671866765494,-0.011930871777798644,-0.9814309777852848,0.008200207580733462,-0.4953285811233533]\n","The Intercept of the model is :  36.75314025390781\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2v_w6Yvy1i2_","executionInfo":{"status":"ok","timestamp":1632876145282,"user_tz":300,"elapsed":1533,"user":{"displayName":"Raúl Valente Ramírez Velarde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsTl_7K9-nt2Nuy6x1vdia7WL7K2k6yyrhPeq3=s64","userId":"12033984646533146741"}},"outputId":"9e101c42-37af-4283-9ca1-923adf6d2c0a"},"source":["#Carry out random forrest regression\n","from pyspark.ml.regression import RandomForestRegressor\n","rfr = RandomForestRegressor(featuresCol = 'Attributes', labelCol = 'medv')\n","\n","#Learn to fit the model from training set\n","rfr = rfr.fit(train_data)\n","\n","#To predict the prices on testing set\n","pred_rfr = rfr.transform(test_data)\n","\n","# Select example rows to display.\n","pred_rfr.select('Attributes', 'medv', 'prediction').show(10)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+----+------------------+\n","|          Attributes|medv|        prediction|\n","+--------------------+----+------------------+\n","|[0.00632,18.0,2.3...|24.0| 28.67275780592778|\n","|[0.00906,90.0,2.9...|32.2|28.232331229956777|\n","|[0.01311,90.0,1.2...|35.4|33.739155780888936|\n","|[0.0187,85.0,4.15...|23.1|23.982504675639657|\n","|[0.01951,17.5,1.3...|33.0|31.847689380064388|\n","|[0.02009,95.0,2.6...|50.0|46.915843018093014|\n","|[0.02187,60.0,2.9...|31.1|29.025862067176604|\n","|[0.02729,0.0,7.07...|34.7| 38.44132210725263|\n","|[0.02731,0.0,7.07...|21.6| 23.44991918071137|\n","|[0.02763,75.0,2.9...|30.8| 27.80914596081069|\n","+--------------------+----+------------------+\n","only showing top 10 rows\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"irU9nIm82wHW","executionInfo":{"status":"ok","timestamp":1632876154713,"user_tz":300,"elapsed":7349,"user":{"displayName":"Raúl Valente Ramírez Velarde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsTl_7K9-nt2Nuy6x1vdia7WL7K2k6yyrhPeq3=s64","userId":"12033984646533146741"}},"outputId":"f839995e-5999-4864-9e9f-7e8648050041"},"source":["#Carry out Gradient-boosted tree regression\n","from pyspark.ml.regression import GBTRegressor\n","gbt = GBTRegressor(featuresCol = 'Attributes', labelCol = 'medv')\n","\n","#Learn to fit the model from training set\n","gbt = gbt.fit(train_data)\n","\n","#To predict the prices on testing set\n","pred_gbt = gbt.transform(test_data)\n","\n","# Select example rows to display.\n","pred_gbt.select('Attributes', 'medv', 'prediction').show(10)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+----+------------------+\n","|          Attributes|medv|        prediction|\n","+--------------------+----+------------------+\n","|[0.00632,18.0,2.3...|24.0|26.283065059360695|\n","|[0.00906,90.0,2.9...|32.2|32.220113745574835|\n","|[0.01311,90.0,1.2...|35.4|  34.9656790467629|\n","|[0.0187,85.0,4.15...|23.1|  22.6350524449578|\n","|[0.01951,17.5,1.3...|33.0| 35.55635889114806|\n","|[0.02009,95.0,2.6...|50.0|  48.5425851394225|\n","|[0.02187,60.0,2.9...|31.1| 34.85967453431064|\n","|[0.02729,0.0,7.07...|34.7| 43.00241130659505|\n","|[0.02731,0.0,7.07...|21.6|23.640480647364864|\n","|[0.02763,75.0,2.9...|30.8| 24.83272778888755|\n","+--------------------+----+------------------+\n","only showing top 10 rows\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"bYORz3Q9wTSW"},"source":["## Analisis Estadistico de la Regresion\n","\n","Once we are done with the basic linear regression operation, we can go a bit further and analyze our model statistically by importing RegressionEvaluator module from Pyspark."]},{"cell_type":"code","metadata":{"id":"8qrQdEj62ptt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632877373117,"user_tz":300,"elapsed":311,"user":{"displayName":"Raúl Valente Ramírez Velarde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsTl_7K9-nt2Nuy6x1vdia7WL7K2k6yyrhPeq3=s64","userId":"12033984646533146741"}},"outputId":"6c1afe10-2a02-409c-9e2c-f6a8d2cc579f"},"source":["from pyspark.ml.evaluation import RegressionEvaluator\n","#Evaluado la regresion lineal\n","eval_lr = RegressionEvaluator(labelCol=\"medv\", predictionCol=\"prediction\", metricName=\"rmse\")\n","\n","print(\"Linear regression model\\n\")\n","\n","# Root Mean Square Error\n","rmse = eval_lr.evaluate(pred_lr)\n","#rmse = eval_lr.evaluate(pred_lr.predictions)\n","print(\"RMSE: %.3f\" % rmse)\n","\n","# Mean Square Error\n","#mse = eval_lr.evaluate(pred_lr.predictions, {eval_lr.metricName: \"mse\"})\n","#print(\"MSE: %.3f\" % mse)\n","\n","# Mean Absolute Error\n","#mae = eval_lr.evaluate(pred_lr.predictions, {eval_lr.metricName: \"mae\"})\n","#print(\"MAE: %.3f\" % mae)\n","\n","# r2 - coefficient of determination\n","#r2 = eval_lr.evaluate(pred_lr.predictions, {eval_lr.metricName: \"r2\"})\n","#print(\"r2: %.3f\" %r2)\n","\n","# r2 - coefficient of determination\n","r2 = eval_lr.evaluate(pred_lr, {eval_lr.metricName: \"r2\"})\n","print(\"r2: %.3f\" %r2)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Linear regression model\n","\n","RMSE: 5.248\n","r2: 0.647\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aVhSn0-a3tKH","executionInfo":{"status":"ok","timestamp":1632876262317,"user_tz":300,"elapsed":674,"user":{"displayName":"Raúl Valente Ramírez Velarde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsTl_7K9-nt2Nuy6x1vdia7WL7K2k6yyrhPeq3=s64","userId":"12033984646533146741"}},"outputId":"82df22dc-3647-4c74-f471-9a7190821e0f"},"source":["eval_rfr = RegressionEvaluator(labelCol=\"medv\", predictionCol=\"prediction\", metricName=\"rmse\")\n","#Evaluando el RFR\n","\n","print(\"Regression Forrest model\\n\")\n","\n","# Root Mean Square Error\n","#rmse = eval_rfr.evaluate(pred_rfr.predictions)\n","rmse = eval_rfr.evaluate(pred_rfr)\n","\n","print(\"RMSE: %.3f\" % rmse)\n","\n","# Mean Square Error\n","mse = eval_rfr.evaluate(pred_rfr, {eval_rfr.metricName: \"mse\"})\n","print(\"MSE: %.3f\" % mse)\n","\n","# Mean Absolute Error\n","mae = eval_rfr.evaluate(pred_rfr, {eval_rfr.metricName: \"mae\"})\n","print(\"MAE: %.3f\" % mae)\n","\n","# r2 - coefficient of determination\n","r2 = eval_rfr.evaluate(pred_rfr, {eval_rfr.metricName: \"r2\"})\n","print(\"r2: %.3f\" %r2)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Regression Forrest model\n","\n","RMSE: 3.419\n","MSE: 11.691\n","MAE: 2.508\n","r2: 0.878\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hnKgVTeP6Cs4","executionInfo":{"status":"ok","timestamp":1632876264415,"user_tz":300,"elapsed":736,"user":{"displayName":"Raúl Valente Ramírez Velarde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsTl_7K9-nt2Nuy6x1vdia7WL7K2k6yyrhPeq3=s64","userId":"12033984646533146741"}},"outputId":"a9bd18d0-e608-451c-fbbb-55ffc506cd1a"},"source":["eval_gbt = RegressionEvaluator(labelCol=\"medv\", predictionCol=\"prediction\", metricName=\"rmse\")\n","#Evaluando GBTR\n","\n","print(\"Gradient Boot Tree model\\n\")\n","\n","# Root Mean Square Error\n","#rmse = eval_rfr.evaluate(pred_rfr.predictions)\n","rmse = eval_gbt.evaluate(pred_gbt)\n","\n","print(\"RMSE: %.3f\" % rmse)\n","\n","# Mean Square Error\n","mse = eval_gbt.evaluate(pred_gbt, {eval_gbt.metricName: \"mse\"})\n","print(\"MSE: %.3f\" % mse)\n","\n","# Mean Absolute Error\n","mae = eval_gbt.evaluate(pred_gbt, {eval_gbt.metricName: \"mae\"})\n","print(\"MAE: %.3f\" % mae)\n","\n","# r2 - coefficient of determination\n","r2 = eval_gbt.evaluate(pred_gbt, {eval_gbt.metricName: \"r2\"})\n","print(\"r2: %.3f\" %r2)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Gradient Boot Tree model\n","\n","RMSE: 3.951\n","MSE: 15.613\n","MAE: 2.881\n","r2: 0.837\n"]}]}]}